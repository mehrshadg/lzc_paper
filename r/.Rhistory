library(readr)
t_test_result <- read_csv("PycharmProjects/analysis-sherlock/misc/t-test_result.csv")
View(t_test_result)
p.adjust(t_test_result$reho_p, method="fdr")
reho = p.adjust(t_test_result$reho_p, method="fdr")
sd = p.adjust(t_test_result$sd_p, method="fdr")
sd < 0.05
which(sd < 0.05)
sd_sig_indices = which(sd < 0.05)
reho_sig_indices = which(reho < 0.05)
sd_sig_indices
sd_sig_indices = sd_sig_indices - 1
sd_sig_indices
library(readxl)
Parcels <- read_excel("PycharmProjects/analysis-sherlock/misc/Parcels.xlsx",
col_types = c("numeric", "text", "blank",
"blank", "text"))
View(Parcels)
sd_sig_indices
sd_sid_parcels = Parcels[Parcels$ParcelID == sd_sig_indices, ]
Parcels$ParcelID == sd_sig_indices
sd_sig_indices %in% Parcels$ParcelID
Parcels$ParcelID %in% sd_sig_indices
sd_sid_parcels = Parcels[Parcels$ParcelID %in% sd_sig_indices, ]
View(sd_sid_parcels)
cbind(sd_sid_parcels$Hem, " ", sd_sid_parcels$Community)
a = cbind(sd_sid_parcels$Hem, " ", sd_sid_parcels$Community)
a = paste(sd_sid_parcels$Hem, sd_sid_parcels$Community)
a
for i in 1: 5
a = as.data.frame(a)
View(a)
View(a)
write_csv(a$a, "sd_regions.csv")
write_csv(a, "sd_regions.csv")
write_csv(a, file="sd_regions.csv")
?dlmwrite
??dlmwrite
write.csv2(a, file="sd_regions.csv")
library(readr)
data <- read_csv("PycharmProjects/analysis-sherlock/misc/t-test_ws_result.csv")
View(data)
?p.adjust()
library(readr)
data <- read_csv("PycharmProjects/analysis-sherlock/misc/t-test_ws_result.csv")
View(data)
data[data$metric==0, ]$p
a = data[data$metric==0, ]$p
?p.adjust()
p.adjust(data[data$metric==0, ]$p, method="fdr")
corrected = p.adjust(data[data$metric==0, ]$p, method="fdr")
which(corrected < 0.05)
reho = data[data$metric==0, ]
reho.corrected = p.adjust(reho$p, method="fdr")
reho.p.corrected = p.adjust(reho$p, method="fdr")
reho.corrected = reho[which(corrected < 0.05), ]
len(which(corrected < 0.05))
length(which(corrected < 0.05))
reho.p.corrected = p.adjust(reho$p, method="bonferroni")
length(which(corrected < 0.05))
library(readr)
data <- read_csv("PycharmProjects/analysis-sherlock/misc/t-test_ws_result_auc.csv")
View(data)
reho = data[data$`# metric`=0, ]
reho = data[data$`# metric`==0, ]
reho.p.corrected = p.adjust(reho$p, method="fdr")
length(which(reho.p.corrected < 0.05))
length(which(reho.p.corrected < 0.001))
length(which(reho.p.corrected < 0.0001))
length(which(reho.p.corrected < 0.00001))
length(which(reho.p.corrected < 0.000001))
length(which(reho.p.corrected < 0.0000001))
length(which(reho.p.corrected < 0.00000001))
length(which(reho.p.corrected < 0.000000001))
length(which(reho.p.corrected < 0.0000000001))
length(which(reho.p.corrected < 0.00000000001))
length(which(reho.p.corrected < 0.000000000001))
length(which(reho.p.corrected < 0.0000000000001))
length(which(reho.p.corrected < 0.00000000000001))
length(which(reho.p.corrected < 0.000000000000001))
length(which(reho.p.corrected < 0.0000000000000001))
length(which(reho.p.corrected < 0.00000000000000001))
length(which(reho.p.corrected < 0.000000000000000001))
length(which(reho.p.corrected < 0.00000000000000001))
which(reho.p.corrected < 0.00000000000000001)
which(reho.p.corrected < 0.01)
which(reho.p.corrected < 0.00000000000000001) - 1
reho[which(reho.p.corrected < 0.00000000000000001), ]
reho.corrected = reho[which(reho.p.corrected < 0.00000000000000001), ]
View(reho.corrected)
as.factor(reho.corrected$region)
View(reho)
as.factor(reho.corrected$ws)
reho.corrected$`# metric`=[]
reho.corrected$`# metric`=non
reho.corrected$`# metric`=na
rm(reho.corrected$`# metric`)
reho.corrected$`# metric`= NONE
reho.corrected$`# metric`= None
reho.corrected$`# metric`= NAN
reho.corrected$`# metric`= NA
View(reho.corrected)
reho.corrected$`# metric`= NULL
View(reho.corrected)
reho.corrected$t= NULL
View(reho.corrected)
reho.corrected = reho[which(reho.p.corrected < 0.05), ]
reho.corrected$t= NULL
reho.corrected$`# metric`= NULL
View(reho.corrected)
write.csv2(reho.corrected, "t-test_ws_result_auc_corrected")
?write.csv2(reho.corrected, "t-test_ws_result_auc_corrected", sep = ",")
?write.csv2(reho.corrected, "t-test_ws_result_auc_corrected", sep = ",")
write.csv2(reho.corrected, "t-test_ws_result_auc_corrected", sep = ",")
write.csv2(reho.corrected, "t-test_ws_result_auc_corrected.csv", sep = ",")
View(reho)
View(reho.corrected)
write_csv(reho.corrected, "t-test_ws_result_auc_corrected.csv")
library(readr)
data <- read_csv("PycharmProjects/analysis-sherlock/window_based/global_dynamic_ttest.csv")
View(data)
type(data$P)
class(data$P)
class(data$T)
class(data$key)
p.adjust(data$P, method="fdr")
adjusted = p.adjust(data$P, method="fdr")
?p.adjust
library(readr)
local <- read_csv("PycharmProjects/analysis-sherlock/window_based/local_dynamic_ttest.csv")
View(local)
library(readr)
global <- read_csv("PycharmProjects/analysis-sherlock/window_based/global_dynamic_ttest.csv")
View(global)
?p.adjust
p.adjust(global, method = "fdr")
p.adjust(global$P, method = "fdr")
p.adjust(global$P, method = "bonferroni")
library(readr)
delete <- read_csv("PycharmProjects/analysis-sherlock/window_based/global_dynamic_ttest (copy).csv")
View(delete)
p.adjust(delete$P, method = "bonferroni")
p.adjust(local$P, method = "bonferroni")
NEI = readRDS("summarySCC_PM25.rds")
SCC = readRDS("Source_Classification_Code.rds")
NEI = readRDS("summarySCC_PM25.rds")
SCC <- readRDS("~/Desktop/exploratory-data-analysis-week4-master/Source_Classification_Code.rds")
NEI <- readRDS("~/Desktop/exploratory-data-analysis-week4-master/summarySCC_PM25.rds")
NEI = readRDS("summarySCC_PM25.rds")
SCC = readRDS("Source_Classification_Code.rds")
aggregatedTotalByYear = aggregate(Emissions ~ year, NEI, sum)
png("plot1.png", width=500, height=500)
barplot(aggregatedTotalByYear$Emissions, names.arg=aggregatedTotalByYear$year, xlab="Years", ylab="Emission", main="Total Emissions")
dev.off()
aggregatedTotalByYear = aggregate(Emissions ~ year, NEI, sum)
png("plot1.png", width=500, height=500)
barplot(aggregatedTotalByYear$Emissions, names.arg=aggregatedTotalByYear$year, xlab="Years", ylab="Emission", main="Total Emissions")
dev.off()
baltimore_NEI = NEI[NEI$fips=="24510", ]
aggregatedTotalByYear = aggregate(Emissions ~ year, baltimore_NEI, sum)
png("plot2.png", width=500, height=500)
barplot(aggregatedTotalByYear$Emissions, names.arg=aggregatedTotalByYear$year, xlab="Years", ylab="Emission", main="Total emissions, Baltimore")
dev.off()
library(ggplot2)
baltimore_NEI = NEI[NEI$fips=="24510", ]
aggregatedTotalByYear = aggregate(Emissions ~ year + type , baltimore_NEI, sum)
png("plot3.png", width=500, height=500)
g = ggplot(aggregatedTotalByYear, aes(year, Emissions, color = type))
g = g + geom_line() + xlab("year") + ylab("Emissions") + ggtitle("Total Emissions, Baltimore (1999-2008)")
print(g)
dev.off()
NEISCC = merge(NEI, SCC, by="SCC")
coalRec = grepl(pattern = 'coal', x = NEISCC$EI.Sector , ignore.case = TRUE )
NEISCC_coal = NEISCC[coalRec,]
aggregatedTotalByYear = aggregate(Emissions ~ year  , NEISCC_coal , sum)
png("plot4.png", width=500, height=500)
g = ggplot(aggregatedTotalByYear, aes(factor(year), Emissions))
g = g + geom_bar(stat="identity") + xlab("year") + ylab("Emissions") + ggtitle("Total Emissions coal combustion-related sources (1999-2008)")
print(g)
dev.off()
baltimore_NEI <- NEI[NEI$fips=="24510" & NEI$type=="ON-ROAD", ]
aggregatedTotalByYear <- aggregate(Emissions ~ year, baltimore_NEI, sum)
png("plot5.png", width=500, height=500)
barplot(aggregatedTotalByYear$Emissions, names.arg=aggregatedTotalByYear$year, xlab="years",ylab="Emission", main="Total emissions, Baltimore")
dev.off()
baltimore_NEI = NEI[NEI$fips=="24510" & NEI$type=="ON-ROAD", ]
la_NEI = NEI[NEI$fips=="06037" & NEI$type=="ON-ROAD", ]
emissionBaltimore  = aggregate(Emissions ~ year, baltimore_NEI, sum)
emissionLa = aggregate(Emissions ~ year, la_NEI, sum)
png("plot6.png",width=960,height=960)
rng = range(emissionBaltimore$Emissions, emissionLa$Emissions)
plot(x = emissionBaltimore$year , y = emissionBaltimore$Emissions, type = "p", pch = 16, col = "blue", ylab = "Emission (in tons)", xlab = "Year",  ylim = rng, main = "Vehicle Emission, LA & Baltimore (1999-2008)")
lines(x =emissionBaltimore$year, y = emissionBaltimore$Emissions, col = "blue")
points(x = emissionLa$year, y = emissionLa$Emissions, pch = 16, col = "green")
lines(x =emissionLa$year, y = emissionLa$Emission, col = "green")
legend("right", legend = c("LA", "Baltimore"), pch = 20, lty=1, col = c("green", "blue"), title = "City")
dev.off()
library(readr)
data <- read_csv("PycharmProjects/analysis_hcp/outputs/mi.anova.csv")
View(data)
library(readr)
data <- read_csv("PycharmProjects/analysis_hcp/outputs/mi.anova.csv")
View(data)
data$group = factor(data$group, levels=unique(data$group))
data$type = factor(data$type, levels=unique(data$type))
library(nlme)
installed.packages('nlme')
installed.packages(nlme)
library(nlme)
library(nlme)
data$subj = factor(data$subj, levels=unique(data$subj))
View(data)
View(data)
View(data)
library(readr)
data <- read_csv("PycharmProjects/analysis_hcp/outputs/mi.anova.csv")
View(data)
data$group = factor(data$group, levels=unique(data$group))
data$type = factor(data$type, levels=unique(data$type))
data$subj = factor(data$subj, levels=unique(data$subj))
data.mean = aggregate(data$type, by=list(data$subj, data$group), FUN='mean')
View(data.mean)
data.mean = aggregate(data$value, by=list(data$type, data$group), FUN='mean')
View(data.mean)
data.aov = with(data, aov(value ~ type * group + Error(subj / (type * group))))
summary(data.aov)
b = TukeyHSD(x=data.aov, 'data$type', conf.level=0.95)
b = TukeyHSD(x=data.aov, data$type, conf.level=0.95)
View(data.aov)
b = TukeyHSD(x=data.aov, conf.level=0.95)
b = TukeyHSD(data.aov, conf.level=0.95)
?TukeyHSD
?aov(value ~ type * group + Error(subj / (type * group)), )
data.anova2 = aov(value ~ type * group + Error(subj / (type * group)), data=data)
b = TukeyHSD(x=data.aov2, 'data$type', conf.level=0.95)
b = TukeyHSD(x=data.anova2, 'data$type', conf.level=0.95)
install.packages('lme4')
library('lme4')
View(data)
data.anova = lmer(value ~ type*group + (1|subj) + (1|type:subj) + (1|group:subj), data=data)
summary(data.anova)
data.model = lmer(value ~ type*group + (1|subj) + (1|type:subj) + (1|group:subj), data=data)
data.anova = anova(data.model)
summary(data.anova)
data.model = lmer(value ~ type*group + (1|subj) + (1|type:subj) + (1|group:subj), data=data)
anova(data.model)
summary(glht(data.model, linfct=mcp(Material = "Tukey")), test = adjusted(type = "bonferroni"))
library('multcomb')
install.packages('multcomb')
require(multcomp)
install.packages('multcomp')
require(multcomp)
summary(glht(data.model, linfct=mcp(Material = "Tukey")), test = adjusted(type = "bonferroni"))
summary(glht(data.model, linfct=mcp(group = "Tukey")), test = adjusted(type = "bonferroni"))
summary(glht(data.model, linfct=mcp(type = "Tukey")), test = adjusted(type = "bonferroni"))
anova(data.model)
summary(data.aov)
data.model = lmer(value ~ type*group + (1|subj) + (1|type:subj) + (1|group:subj), data=data)
anova(data.model)
summary(glht(data.model, linfct=mcp(group = "Tukey")), test = adjusted(type = "bonferroni"))
summary(glht(data.model, linfct=mcp(type = "Tukey")), test = adjusted(type = "bonferroni"))
data = read_csv("outputs/pearson.subj.anova.csv")
library('lme4')
require(multcomp)
library(readr)
data = read_csv("outputs/pearson.subj.anova.csv")
data = read_csv("PycharmProjects/analysis_hcp/outputs/pearson.subj.anova.csv")
View(data)
unique(data$metric)
as.factor(unique(data$metric))
as.factor(data$metric, levels=unique(data$metric))
?as.factor
as.factor(data$metric, unique(data$metric))
data = within(data, {
metric = factor(metric)
mask = factor(mask)
group = factor(group)
})
for (metric in unique(data$metric)) {
print(metric)
}
metric_names = c("sd", "reho2d.cortex", "dfa", "lzc")
data = read_csv("PycharmProjects/analysis_hcp/outputs/pearson.index.anova.csv")
data = read_csv("PycharmProjects/analysis_hcp/outputs/pearson.subj.anova.csv")
View(data)
data = within(data, {
index = factor(index)
metric = factor(metric)
mask = factor(mask)
group = factor(group)
index_label = factor(index_label)
})
library('lme4')
require(multcomp)
library(readr)
metric_names = c("sd", "reho2d.cortex", "dfa", "lzc")
data = read_csv("PycharmProjects/analysis_hcp/outputs/pearson.subj.anova.csv")
data = within(data, {
index = factor(index)
metric = factor(metric)
mask = factor(mask)
group = factor(group)
index_label = factor(index_label)
})
for (metric in unique(data$metric)) {
data_metric = data[data$metric == metric, ]
print(metric_names[metric])
data.aov = with(data_metric, aov(value ~ mask * group + Error(index / (mask * group))))
summary(data.aov)
data.model = lmer(value ~ mask*group + (1|index) + (1|mask:index) + (1|group:index), data=data_metric)
anova(data.model)
summary(glht(data.model, linfct=mcp(group = "Tukey")), test = adjusted(type = "bonferroni"))
summary(glht(data.model, linfct=mcp(mask = "Tukey")), test = adjusted(type = "bonferroni"))
}
print(metric_names[as.numeric(metric)])
metric_names[as.numeric(metric)]
data.aov = with(data_metric, aov(value ~ mask * group + Error(index / (mask * group))))
data.model = lmer(value ~ mask*group + (1|index) + (1|mask:index) + (1|group:index), data=data_metric)
anova(data.model)
summary(glht(data.model, linfct=mcp(group = "Tukey")), test = adjusted(type = "bonferroni"))
summary(glht(data.model, linfct=mcp(mask = "Tukey")), test = adjusted(type = "bonferroni"))
library(readr)
data <- read_csv("PycharmProjects/analysis_hcp/outputs/pearson.subj.anova.csv")
View(data)
print("a")
source('~/delete.R')
a = c("A", "B")
a[0]
a(0)
require(car)
require(MASS)
qqp
?qqp
wilcox.test(x, y, paired = TRUE, alternative = "two.sided")
data <- read.table("NC_ACF_alltasks.csv", header=FALSE,
sep=",")
data <- read.table("/home/mehrshad/Desktop/sh/NC_ACF_alltasks.csv", header=FALSE,
sep=",")
data <- read.table("/home/mehrshad/Desktop/sh/NC_ACF_alltasks.csv", header=FALSE,
sep=",")
data[data==0] <- NA
p_valence <- 0
f_valence <- 0
p_speed <- 0
f_speed <- 0
p_Val_Sp <- 0
f_Val_Sp <- 0
library('lme4')
install.packages(lme4)
install.packages("lme4")
i=1
data_long <- data[,i]
ACFData <- data.frame(PID = gl(32,4,128),
ACF = data_long,
Valence = gl(2, 2, 128, label = c("Negative", "Neutral"),
ordered = FALSE),
Speed = gl(2, 1, 128, label = c("Slow", "Fast"),
ordered = FALSE)
)
inds <- is.nan(ACFData$ACF)
ACFData$ACF[inds] <- NA
ACFData <- within(ACFData, {
PID   <- factor(PID)
Valence <- factor(Valence)
Speed <- factor(Speed)
})
ACFData <- ACFData[order(ACFData$PID), ]
#head(ACFData)
data.model = lmer(ACF ~ Valence*Speed + (1|PID), data=ACFData)
anova(data.model)
library("lme4")
data_long <- data[,i]
ACFData <- data.frame(PID = gl(32,4,128),
ACF = data_long,
Valence = gl(2, 2, 128, label = c("Negative", "Neutral"),
ordered = FALSE),
Speed = gl(2, 1, 128, label = c("Slow", "Fast"),
ordered = FALSE)
)
inds <- is.nan(ACFData$ACF)
ACFData$ACF[inds] <- NA
ACFData <- within(ACFData, {
PID   <- factor(PID)
Valence <- factor(Valence)
Speed <- factor(Speed)
})
ACFData <- ACFData[order(ACFData$PID), ]
#head(ACFData)
data.model = lmer(ACF ~ Valence*Speed + (1|PID), data=ACFData)
anova(data.model)
summary(data.model)
require(MASS)
require(car)
require("DescTools")
library(emmeans)
library(multcomp)
require(effsize)
summary(data.model)
Anova(data.model)
setwd("~/remote/share/mg/lzc_paper/r")
library(feather)
# df = read_feather("med_model_1.feather")
df = read.csv2("med_model_1.csv")
d("~/remote/share/mg/lzc_paper/r")
library(feather)
# df = read_feather("med_model_1.feather")
df = read.csv2("med_model_1.csv")
View(df)
# df = read_feather("med_model_1.feather")
df = read.csv2("med_model_1.csv", sep=",")
View(df)
fit.totaleffect = lm(lzc_task ~ lzc_rest, df)
fit.totaleffect = lm("lzc_task ~ lzc_rest", df)
View(df)
fit.totaleffect = lm("lzc_movie ~ lzc_rest", df)
df.summary()
df$lzc_rest
df = within(df, rm(x))
df = within(df, rm("X"))
df = within(df, {
region = factor(region)
subject = as.numeric(subject)
lzc_movie = as.numeric(lzc_movie)
lzc_ret = as.numeric(lzc_ret)
lzc_rest = as.numeric(lzc_rest)
mf_rest = as.numeric(mf_rest)
})
df#mf_rest
df$mf_rest
# df = read_feather("med_model_1.feather")
df = read.csv2("med_model_1.csv", sep=",")
df = within(df, rm("X"))
df = within(df, {
region = factor(region)
subject = as.numeric(subject)
lzc_movie = as.double(lzc_movie)
lzc_ret = as.double(lzc_ret)
lzc_rest = as.double(lzc_rest)
mf_rest = as.double(mf_rest)
})
df = read.csv2("med_model_1.csv", sep=",")
df = within(df, rm("X"))
df = within(df, {
region = factor(region)
subject = as.numeric(subject)
lzc_movie = as.double(levels(lzc_movie))
lzc_ret = as.double(lzc_ret)
lzc_rest = as.double(lzc_rest)
mf_rest = as.double(mf_rest)
})
# df = read_feather("med_model_1.feather")
df = read.csv2("med_model_1.csv", sep=",", colClasses=c("numeric", rep("factor", 2), rep("numeric",4)))
# df = read_feather("med_model_1.feather")
df = read.csv2("med_model_1.csv", sep=",", colClasses=c("numeric", rep("factor", 2), rep("double",4)))
df = read_feather("med_model_1.feather")
df$lzc_movie
type df$lzc_movie
type (df$lzc_movie)
View(df)
fit.totaleffect = lm(lzc_movie ~ lzc_rest, df)
summary(fit.totaleffect)
out = summary(fit.totaleffect)
fit.mediator = lm(mf_rest ~ lzc_rest, df)
summary(fit.mediator)
fit.dv = lm(lzc_movie ~ lzc_rest + mf_rest, df)
summary(fit.dv)
install.packages("mediation")
library(mediation)
results = mediate(fit.mediator, fit.dv, treat='lzc_rest', mediator='mf_rest’)
setwd("~/remote/share/mg/lzc_paper/r")
library(feather)
df = read_feather("med_model_1.feather")
fit.totaleffect = lm(lzc_movie ~ lzc_rest, df)
summary(fit.totaleffect)
fit.mediator = lm(mf_rest ~ lzc_rest, df)
summary(fit.mediator)
fit.dv = lm(lzc_movie ~ lzc_rest + mf_rest, df)
summary(fit.dv)
library(mediation)
results = mediate(fit.mediator, fit.dv, treat='lzc_rest', mediator='mf_rest')
summary(results)
